[["index.html", "Cherin-Juliette | Portfolio 1 Hi there! 1.1 About Me 1.2 Future Ambitions 1.3 My Resume 1.4 Expanding My Skill Set", " Cherin-Juliette | Portfolio 2022-06-06 1 Hi there! 1.1 About Me I’m a Molecular Biologist with a passion for data science. Currently I’m looking for an internship that combines laboratory work with data science. 1.2 Future Ambitions Now that I’ve been given the tools to undertake basic Data Science analysis, my ultimate objective is to be a Molecular Biologist with professional Data Science skills. I’ve designed a three-step approach to achieve my aim of learning the programming languages Bash and R. These steps are time blocks of three months, one year, and five years in which I will pursue an internship that mixes lab work with Data Science analysis and then pursue a position that will allow me to advance and gain expertise in my profession. 1.2.1 3 Months Goals RNA Sequence Analysis in R During the minor I performed a RNA sequencing analysis of the ONECUT2 gene. To practice with this analysis I will import SRA identifiers from the BTK gene, and perform the analysis in R. Mutated BTK genes cause faulty B-cell formation which in turn causes the disease X-Linked Agammaglobulinemia (XLA). Previously during my studies I did a project on the laboratory which included mutation analysis of healthy patients and patients with XLA in DNAbaser. To make this analysis more time efficient I will do this in R. Sentiment Analysis of All Literature by Edgar Allan Poe This has been something which I have wanted to do for years. When studying literature the climax and denouement of a novel is determined by a specific undertone, however I wish to prove these segments with sentiment analysis. After all, as Heinrich von Schlegel said Every art should become science, and every science should become art. Gender Determination of the Corvus Corax This was the last project I worked on before beginning the minor in Data Science. The commissioning party consisted of a group of birders who worked under the direction of a professor at my college. NO2 and isopropanol were used to extract DNA from feathers. The DNA was then amplified using a HotStart PCR and custom primers. Because the physical distinctions of the Corvus corax are difficult to identify when comparing genders, I will create a dataset in SQL and compare the phenotypes of the birds with the PCR results in R. This is an ongoing project however and therefore completion within the self-given timeframe is not viable. 1.2.2 1 Year Goals This is the year I’ll be doing an internship in a laboratory. In addition to expanding on my present knowledge with laboratory procedures, I intend to use this year to hone my Data Science skills. How will I accomplish this? While data science is a flourishing field, not many laboratories fully utilize its capabilities. The key goal is to apply my existing skills to the project that I will be working on during my internship and then expand on these by improving an analysis that they routinely perform. In addition to this, I will continue the project Gender Determination of the Corvus corax in R. Improving an extisting analysis in the laboratory in which I follow an internship. Gender Determination of the Corvus corax using PCR. I will do this by adding new found data to the existing SQL database and comparing the phenotype with the results acquired by PCR. 1.2.3 5 Years Goals In five years time I will have finished my degree and started my first job that uses my degree. These are the years in which I may fully focus on honing my Data Science skills. This is because I will have a minor in Data Science as well as an internship which may add to my credentials. To reach my objective of becoming a proficient Data Scientist. See what point I will focus on below. Gain more experience with DNA isolation. My educational background has provided me with many opportunities during which I couuld practice DNA isolation with. There are several methods for DNA isolation, primarily with the isopropanol method and ethanol extraction, and I would like to develop my skills in DNA isolation with the Chelex method. Gain more experience with sequencing. My experience with sequencing as of yet is purely theoretical. Sequencing however, either with DNA or RNA can provide us with much more profound information in Genetics. This is why, through my job, I will seek to gain practical experience with sequencing. Gain more experience with mutation analysis in Bash and R. In genetics and in medicine the benefits of mutation analysis is recognized. Through my job I will seek to build on my previous experiences, provided by my education, with mutation analysis. Make an interactive and elaborate R Shiny app that tracks pet health. This project is intended to help me fully and intrinsically understand R Shiny, which may be supplemented with HTML and CSS. I will first do this by making an health monitor in R Shiny for my pet, and then apply this method to something more universal. This way the universal may then also be used for (my) other pets. Sentiment Analysis of Several Other Novels. This is also a short term goal however to get a better feel for this I will apply sentiment analysis in R to several other novels. Keywords: sentiment analysis, R Learn for to use Pandas from Python. Pandas is frequently used in data science and performs functions comparable to those found in R. To broaden my Data Scientist skills, I will learn how to use Pandas from Python. Data Cleaning in SQL Data cleaning is a very big part of Data Science and Data Analysis. When we wish to analyse data retrieved from areas where tidy data or agile workflows are not used, data must first be cleaned. Currently I only do this with the janitor package in R, I would like to clean data in SQL before tidying in R. 1.3 My Resume cherin.mohamed@hu.student.nl github.com/cherjuliette. I’m currently looking for an internship that combines Data Science with Molecular Biology. Now that my minor Data Science is nearing the end and I am specialized in Molecular Biology, I am looking for an internship which would allow me to improve my programming skills while also facilitating my laboratory experiences. 1.3.1 Education Institute for Life Sciences (HU) B.S. in Molecular Biology Utrecht, The Netherlands 2023 Specialization courses: Biotechnology, Advanced Labtools, Tumorcell biology Minor: Data Science using Bash, R Vocational School Beverwijk Vocational Education diploma (MBO) in Biotechnology Beverwijk, The Netherlands 2015 During my studies I was taught the preliminary experiments for big researches which has resulted in my experience with laboratory techniques such as bacteria identification and PCR. 1.3.2 Research Experience Automating Peak Identification using R Institute for Life Sciences (HU) Utrecht, The Netherlands March 2022 - June 2022 I was involved in writing a for-loop in R which counted the number of peaks and calculated the beats per minute (BPM). Made a R Shiny app for graph visualization to make the analysis easier for second year students. Mutation Analysis of the BTK gene Institute of Life Sciences Institute for Life Sciences (HU) Utrecht, The Netherlands 2018 The immune deficiency X‑linked agammaglobulinemia (XLA) is caused by mutations in the beta tyrosine kinase (BTK) gene. The weakened immune system is directly related to faulty B‑cell formation. DNA was isolated and amplified using PCR from XLA patients and healthy patients. Custom primers were created to target the BTK gene, which was then sequenced. The location of mutations was discovered using the software DNA baser. 1.3.3 Work Experience Freelance literary critic Online 2020 - 2022 Writers contact me and request that I read their novels, following which I provide feedback on the syntax and content. The review is available on Goodreads and Instagram, and it is always accompanied by an attractive photo or video. Employee at the Biobank BioBank Amsterdam UMC (Previously VuMC) June 2016 – September 2016 My duties included separating Polymorphonuclear leukocytes (PMNs) from whole blood and storing body fluids. Intern at the Biobank BioBank Amsterdam UMC (Previously VuMC) September 2015 - June 2016 My duties primarily included separating Polymorphonuclear leukocytes (PMNs) from whole blood, storing body fluids and prepare blood sam‑ ples for tests. Intern at the Waterlaboratory (Het Waterlaboratorium) Waterlaboratory Haarlem Quality assurance; Legionella detection on BCYE medium; Bacteria identification using MALDI‑TOFF. 1.3.4 Honors Courses Postmodernity and American Culture English department at the Institute University of Applied Sciences Utrecht, The Netherlands 2021 Throughout the course, I learned about America’s role in the twenty‑first century, as well as the importance of communication in politics. Fur‑ thermore, this course has greatly improved my English proficiency. American Literature University of Applied Sciences Utrecht, The Netherlands 2021 The literary framework of poetry and novels was taught to me. I was also taught about Western American literature written during the Great Migration. This course has helped me improve my English skills. Debating in English University of Applied Sciences Utrecht, The Netherlands 2020 Throughout the course, I was given a variety of topics to debate from various perspectives. Aside from improving my English speaking skills, I was also taught how to debate respectfully. 1.4 Expanding My Skill Set During my minor course Data Science I was presented with the option of expanding my skills by learning basic skills of a new programming language in (at least) 32 hours. I chose to fill this time by learning how to use HTML and CSS. Why did I do this? Not because I have any aspirations of becoming a UI or UX designer however during my life, especially in the last view years, I often stumbled upon moments during which I wished I had basic skills with HTML. Currently I am participating in a project that automates peak identification for which I need to make a R Shiny app. After I have finished the minor I intend to practice using R Shiny by making an app that stores and shows the medical history of my pet. That process implements HTML and CSS quite heavily, at least if you want the app to become more elaborate. To help myself in this process I have made a HTML portfolio in which I display all my projects that I show here. "],["reproducibility-in-data-science.html", "2 Reproducibility in Data Science", " 2 Reproducibility in Data Science At the institute for Life Sciences a dose response analysis was performed on the C. elegans. The effect of compounds Decane, Naphthalene and 2,6-diisopropylnaphthalene were the number of offspring. From the course instructors I have acquired a dataset which contains the number of offspring and the concentrations of the compounds. In R I visualize the effects using ggplot2. The main objective of the experiment was to establish whether the compounds Decane, Nephtalene and 2,6-diisopropylnaphthalene causes a decrease in the number of offpsring seen in the C. elegans and if so, in what concentrations. Ethanol was used as a positive control, meaning the number of offspring will definitely drop when being exposed to it. S-medium was used as a negative control, which means nothing will happen when the C. elegans is exposed to it. 68 hours after exposure the number of offspring were counted under a microscope. In R, I loaded the dataset and inspected it. The column RawData contains the number of offspring after 68 hours of exposure to the compounds. The column compName shows the compound to which C. elegans was exposed to and lastly the column compConcentration shows the concentration of the compound. A problem I came across was that the column compConcentration was classified as a character rather than numeric. The reason for this is because the value separator was a comma instead of a fullstop. A way of changing is is by using the as.numeric function however that will result in values being removed. Alternatively, using the str_replace function works better and will not remove any values. Load packages Data import Inspect data Clean data Tidy data Visualization Conclusions ## import the data as a dataframe using read_xlsx ## by default sheet1 will be imported df &lt;- as.data.frame(readxl::read_xlsx(here::here( &quot;raw_data/CE.LIQ.FLOW.062_Tidydata.xlsx&quot;))) ## inspect the data dplyr::glimpse(df) ## Rows: 360 ## Columns: 34 ## $ plateRow &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ plateColumn &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ vialNr &lt;dbl&gt; 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 1, 1,… ## $ dropCode &lt;chr&gt; &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, &quot;a&quot;, &quot;b&quot;, &quot;c&quot;, &quot;d&quot;, &quot;e&quot;, … ## $ expType &lt;chr&gt; &quot;experiment&quot;, &quot;experiment&quot;, &quot;experiment&quot;, &quot;experim… ## $ expReplicate &lt;dbl&gt; 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,… ## $ expName &lt;chr&gt; &quot;CE.LIQ.FLOW.062&quot;, &quot;CE.LIQ.FLOW.062&quot;, &quot;CE.LIQ.FLOW… ## $ expDate &lt;dttm&gt; 2020-11-30, 2020-11-30, 2020-11-30, 2020-11-30, 2… ## $ expResearcher &lt;chr&gt; &quot;Sergio Reijnders - Ellis Herder&quot;, &quot;Sergio Reijnde… ## $ expTime &lt;dbl&gt; 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68, 68… ## $ expUnit &lt;chr&gt; &quot;hour&quot;, &quot;hour&quot;, &quot;hour&quot;, &quot;hour&quot;, &quot;hour&quot;, &quot;hour&quot;, &quot;h… ## $ expVolumeCounted &lt;dbl&gt; 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50, 50… ## $ RawData &lt;dbl&gt; 44, 37, 45, 47, 41, 35, 41, 36, 40, 38, 44, 48, 43… ## $ compCASRN &lt;chr&gt; &quot;24157-81-1&quot;, &quot;24157-81-1&quot;, &quot;24157-81-1&quot;, &quot;24157-8… ## $ compName &lt;chr&gt; &quot;2,6-diisopropylnaphthalene&quot;, &quot;2,6-diisopropylnaph… ## $ compConcentration &lt;chr&gt; &quot;4.99&quot;, &quot;4.99&quot;, &quot;4.99&quot;, &quot;4.99&quot;, &quot;4.99&quot;, &quot;4.99&quot;, &quot;4… ## $ compUnit &lt;chr&gt; &quot;nM&quot;, &quot;nM&quot;, &quot;nM&quot;, &quot;nM&quot;, &quot;nM&quot;, &quot;nM&quot;, &quot;nM&quot;, &quot;nM&quot;, &quot;n… ## $ compDelivery &lt;chr&gt; &quot;Liquid&quot;, &quot;Liquid&quot;, &quot;Liquid&quot;, &quot;Liquid&quot;, &quot;Liquid&quot;, … ## $ compVehicle &lt;chr&gt; &quot;controlVehicleA&quot;, &quot;controlVehicleA&quot;, &quot;controlVehi… ## $ elegansStrain &lt;chr&gt; &quot;N2&quot;, &quot;N2&quot;, &quot;N2&quot;, &quot;N2&quot;, &quot;N2&quot;, &quot;N2&quot;, &quot;N2&quot;, &quot;N2&quot;, &quot;N… ## $ elegansInput &lt;dbl&gt; 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25… ## $ bacterialStrain &lt;chr&gt; &quot;OP50&quot;, &quot;OP50&quot;, &quot;OP50&quot;, &quot;OP50&quot;, &quot;OP50&quot;, &quot;OP50&quot;, &quot;O… ## $ bacterialTreatment &lt;chr&gt; &quot;heated&quot;, &quot;heated&quot;, &quot;heated&quot;, &quot;heated&quot;, &quot;heated&quot;, … ## $ bacterialOD600 &lt;dbl&gt; 0.743, 0.743, 0.743, 0.743, 0.743, 0.743, 0.743, 0… ## $ bacterialConcX &lt;dbl&gt; 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8,… ## $ bacterialVolume &lt;dbl&gt; 300, 300, 300, 300, 300, 300, 300, 300, 300, 300, … ## $ bacterialVolUnit &lt;chr&gt; &quot;ul&quot;, &quot;ul&quot;, &quot;ul&quot;, &quot;ul&quot;, &quot;ul&quot;, &quot;ul&quot;, &quot;ul&quot;, &quot;ul&quot;, &quot;u… ## $ incubationVial &lt;chr&gt; &quot;1,5 glass vial&quot;, &quot;1,5 glass vial&quot;, &quot;1,5 glass via… ## $ incubationVolume &lt;dbl&gt; 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 10… ## $ incubationUnit &lt;chr&gt; &quot;ul&quot;, &quot;ul&quot;, &quot;ul&quot;, &quot;ul&quot;, &quot;ul&quot;, &quot;ul&quot;, &quot;ul&quot;, &quot;ul&quot;, &quot;u… ## $ incubationMethod &lt;chr&gt; &quot;rockroll&quot;, &quot;rockroll&quot;, &quot;rockroll&quot;, &quot;rockroll&quot;, &quot;r… ## $ incubationRPM &lt;dbl&gt; 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35, 35… ## $ bubble &lt;lgl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ incubateTemperature &lt;dbl&gt; 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20… df %&gt;% ggplot(aes(x = compConcentration, y = RawData, color = compName, shape = expType)) + geom_point() + theme_minimal() + labs(title = &quot;Dose Response Reaction of\\nDecane, Nepthalane and 2,6-diisopropylnaphthalene&quot;, subtitle = &quot;Data collected after 68 hours of dose response time&quot;, x = &quot;Compound concentration in nM&quot;, y = &quot;Number of offspring at 68 hours&quot;, caption = &quot;Data source: J. Louter of the Institute of Life Sciences&quot;) + scale_color_rcolorUtrecht(palette = &quot;miffy&quot;) This dataset was a good way to practice with data normalization considering the positively skewed plot. This makes the data difficult to read, which means I needed to do a log10 transformation. ## the data is difficult to interpret ## perform a log10 analysis on the compConcentration df %&gt;% ggplot(aes(x = (log10(compConcentration + 0.001)), y = RawData, color = compName, shape = expType)) + geom_point() + geom_jitter(position = position_jitter(0.2)) + theme_minimal() + scale_color_rcolorUtrecht(palette = &quot;miffy&quot;) + labs(title = &quot;Dose Response Reaction of\\nDecane, Nepthalane and 2,6-diisopropylnaphthalene&quot;, subtitle = &quot;Data collected after 68 hours of dose response time&quot;, x = &quot;Compound concentration in nM&quot;, y = &quot;Number of offspring at 68 hours&quot;, caption = &quot;Data source: J. Louter of the Institute of Life Sciences&quot;) A log10 transformation helps with interpreting results. The higher the concentration, the less offspring is counted. After this, I normalized the data for the negative control. Why? To get a more relative view of the experiment. If I calculate the mean value for the negative control and then normalize those values, I can compare each data point with that normalized control. This way we may get a more relative conclusion of the plot. ## to make the results more relative ## summarize the data of the negative control ethanol_summary &lt;- df %&gt;% group_by(compName, compConcentration) %&gt;% summarize(by = &quot;compName&quot;, mean = mean(RawData, na.rm = TRUE)) ## check the mean value of the ethanol values ethanol &lt;- df$RawData[df$expType==&quot;controlNegative&quot;] %&gt;% mean() ##85.9 ## normalize the results for the negative control ethanol_summary &lt;- ethanol_summary %&gt;% mutate(normalized_mean = mean / 85.9) ## and compare each value with this normalized data ethanol_summary %&gt;% ggplot(aes(x = (log10(compConcentration + 0.001)), y = normalized_mean, colour = compName, shape = compName)) + geom_point() + geom_line() + labs(title = &quot;Dose Response Reaction of\\nDecane, Nepthalane and 2,6-diisopropylnaphthalene&quot;, x = &quot;Compound concentration in nM&quot;, y = &quot;Number of offspring&quot;) + theme_minimal() + scale_color_rcolorUtrecht(palette = &quot;miffy&quot;) What can be concluded from this graph is that with increasing concentrations the number of offspring also drop. However what we can see now, what we couldn’t before is that Naphthalene shows the most severe drop in offspring, becoming more severe with higher concentrations. This is a predictable conclusion, but also has shortcomings because it says little about the IC50 and EC50. A way to establish a conclusion on these factors would be to use the drc package. See my source code in file named 001_dsfb2_celegans.Rmd. The data file is named CE.LIQ.FLOW.062_Tidydata.xlsx and may be found in the folder raw_data. To understand how I applied the Guerilla Method to manage my files, take a look at my article Data &amp; File management References: A Brief Introduction to C. elegans C. elegans dataset provided by the course instructors, however the experiment was conducted by J. Louter. "],["dose-response-analysis-of-c.-elegans.html", "3 Dose Response Analysis of C. elegans", " 3 Dose Response Analysis of C. elegans All truth is one. In this light may science and religion labor here together for the steady evolution of mankind; from darkness to light; from prejudice to tolerance; from narrowness to broadmindedness. It is the voice of life that calls us to come and learn. (Edmund B. Hayes Hall, Buffalo University) Science is not a static concept. It is just as dynamic as the world we live in. We are constantly presented with new research questions evident from the million papers that are published each year. So why is it that people claim there is a reproducility crisis in science? Reproducility is the concept that if a group of researcher want to determine what color the sky is, and they conclude with blue, the group of researcher who want to verify this conclusion should see results almost identical to their predecessors. So why is something that sounds so logical and simple rare? And why is it that reproducibility and transparancy became such a big deal only a few years ago? Well..while it cannot be explained away by some cynical reason, it can be agreed upon that errors can hide in the smallest corners. From contaminated pipet tips to a researcher who had forgotten to write down a certain step in the protocol. If a research is not reproducible, its conclusion must be disregarded. While Standford researcher Dr. John Loannidis claimed that the vast majority of research claims are false! A reason for reproducibility is that it benefits a company or institution. If the data gathered by a researcher or research group is openly assessisble (in the company at least), weak or faulty statements are more easily spotted and corrected. This makes a company self-sufficient, efficient and more trustworthy in the eyes of the public. A way of assuring reproducibility is by using the STAR method. STAR stands for Structured, Transparant, Accessible and Reporting. The method states that all data and analysis used for the research should be neatly organized in a clear file structure. See how I manage my files using the Guerilla Method on my portfolio! Many researchers have taken on the STAR method by changing their way of analysing. An example I will give you is a research by microbiologist and data scientist Riffomonas. In a research on global COVID-19 vaccination intent, he has shared his code and data with which he performed the analysis which I will duplicate. This analysis focuses on the global consensus on the COVID-19 vaccin in August 2020 to September 2020. data &lt;- read_csv(here::here(&quot;raw_data&quot;, &quot;august_october_2020.csv&quot;)) %&gt;% rename(country = X.1, percent_august = &quot;Total Agree - August 2020&quot;, percent_october = &quot;Total Agree - October 2020&quot;) %&gt;% mutate(bump_august = if_else(percent_august &lt; percent_october, percent_august - 2, percent_august + 2), bump_october = if_else(percent_august &lt; percent_october, percent_october + 2, percent_october - 2)) main_plot &lt;- data %&gt;% pivot_longer(cols = -country, names_to=c(&quot;.value&quot;, &quot;month&quot;), names_sep = &quot;_&quot;) %&gt;% mutate(country = factor(country, levels = rev(data$country))) %&gt;% ggplot(aes(x=percent, y=country, color=month)) + geom_line(color=&quot;#e6e6e6&quot;, size=1.75, show.legend = FALSE) + geom_point(size=2, show.legend = FALSE) + geom_text(aes(label=glue(&quot;{percent}%&quot;), x=bump),size=3, show.legend = FALSE) + scale_color_manual(name=NULL, breaks=c(&quot;august&quot;, &quot;october&quot;), values=c(&quot;#727272&quot;, &quot;#15607a&quot;), labels=c(&quot;August&quot;, &quot;October&quot;)) + scale_x_continuous(limits=c(50, 100), breaks=seq(50, 100, by=5), labels=glue(&quot;{seq(50, 100, 5)}%&quot;)) + labs(x=NULL, y=NULL, title=&quot;If a vaccine for COVID-19 were available, I would get it&quot;, caption=&quot;&lt;i&gt;Base: 18,526 online adults aged 16-74 across 15 countries&lt;/i&gt;&lt;br&gt;Source: Ipsos&quot;)+ theme( plot.title.position = &quot;plot&quot;, plot.title = element_text(face=&quot;bold&quot;, margin= margin(b=20)), plot.caption = element_markdown(hjust=0, color=&quot;darkgray&quot;), plot.caption.position = &quot;plot&quot;, panel.background = element_blank(), axis.ticks = element_blank(), axis.text.x = element_text(color=&quot;darkgray&quot;), panel.grid.major.x = element_line(color=&quot;gray&quot;, size=0.1), panel.grid.major.y = element_line(color=&quot;gray&quot;, size=0.1, linetype=&quot;dotted&quot;) ) total &lt;- data %&gt;% filter(country == &quot;Total&quot;) %&gt;% pivot_longer(cols = -country, names_to=c(&quot;.value&quot;, &quot;month&quot;), names_sep = &quot;_&quot;) %&gt;% mutate(pretty = if_else(month == &quot;august&quot;, &quot;Total Agree -&lt;br&gt;August 2020&quot;, &quot;Total Agree -&lt;br&gt;October 2020&quot;), align = if_else(month == &quot;august&quot;, 0, 1)) main_plot + coord_cartesian(clip=&quot;off&quot;) + geom_textbox(data=total, aes(x=percent, y =country, color=month, label=pretty, hjust=align), size=2, box.color=NA, width=NULL, vjust=-0.5, box.padding=margin(0,0,0,0), fill=NA, show.legend=FALSE) ggsave(&quot;august_october_2020_ipsos.tiff&quot;, width=6, height=4) Adaption 1: I had to change the working directory with the here package. This is because I keep a separate file for all data. In August, China showed the highest incentive for accepting a vaccine, before one was available. Following China, Brazil, Australia and India showed the highest motivation for getting a vaccine. Contrasting China, France showed most reluctance, closely followed by the United States and Italy. The analysis that I reproduced was entirely written by Riffomonas, who has a Youtube channel a website and a GitHub account where he shares his code. So, for the criteria of accessibility, author information and code availability he gets an A+. So, this seemed easy right? Someone shared a file and we run their code and rejoice when seeing a plot. But analysis like these are easier to replicate because their so small and because COVID-19 had such a overwhelming presence in the world that it was in everyone’s best interest to share as much information as possible. In a sense, this was the first global group project. However, imagine if this was a standard research, in the lab and with code that we have to reproduce. That’s much more difficult, let me show you why. From the Journal website I took the article Plasma ACE2 predicts outcome of COVID-19 in hospitalized patients written by Bibby, B.M.; et al. and attempted to replicate the code. The code may be downloaded in a zip-file, which contains two seperate files. Before downloaded you are helpfully redirected to a page which explains the content of each folder. Our body is made up of cells and it so happens that the cells in our lungs have receptors on the outside layer. The article explains that the COVID-19 virus binds to the angiotensin converting enzyme 2 (ACE2), the virus can more easily nestle in the body causing a more severe response in the person. The article tries to establish whether it can be predicted how sick people will become after infection, depending on the number of ACE enzymes present in plasma. In R, I imported the data file and attempted to reproduce the analysis. However the first problem I encountered was that the source data was not shared on the site. While many research groups have started to share their data, they often refrain from sharing source code making reproducibility more difficult to achieve. Nevertheless, I have attempted to visualize the data to the best of my ability and have then scored the study on reproducibility using the transparency criteria. Problems that I came across were: It seemed as if the README was missing, however descriptions of the variables were stored in an Excel sheet named Variable_descriptions_2021-04-27 which I at first mistook for the file containing the data. The source code was unavailable so I had to guess as to how I was meant to reproduce the analysis in R. The README does not contain metadata on the files. Before downloading the data, you are redirected to a page with descriptions on the files however if you download the files now but do the analysis in a few days you will have already forgotten precisely what the difference is between the files and will waste time having to look it up Just a disclaimer, this is in no way a criticism of the analists who did this research but I’m merely stating the issues I came across when duplicating the analysis. When considering the transparency criteria, I would score this research 5 out of 8 points. ## import the dataset df &lt;- read_delim(here::here(&quot;raw_data/MGH_Olink_COVID_Apr_27_2021/MGH_COVID_Clinical_Info.txt&quot;)) ## let&#39;s take a look head(df) ## # A tibble: 6 × 44 ## subject_id COVID Age_cat BMI_cat HEART LUNG KIDNEY DIABETES HTN IMMUNO ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 1 4 0 0 0 0 0 0 ## 2 2 1 2 2 0 0 0 0 0 0 ## 3 3 1 3 4 0 1 0 0 0 0 ## 4 4 1 1 2 0 0 0 0 0 0 ## 5 5 1 3 3 0 0 0 1 1 0 ## 6 6 1 1 1 1 0 0 0 0 0 ## # … with 34 more variables: Resp_Symp &lt;dbl&gt;, Fever_Sympt &lt;dbl&gt;, GI_Symp &lt;dbl&gt;, ## # D0_draw &lt;dbl&gt;, D3_draw &lt;dbl&gt;, D7_draw &lt;dbl&gt;, DE_draw &lt;dbl&gt;, Acuity_0 &lt;dbl&gt;, ## # Acuity_3 &lt;dbl&gt;, Acuity_7 &lt;dbl&gt;, Acuity_28 &lt;dbl&gt;, Acuity_max &lt;dbl&gt;, ## # abs_neut_0_cat &lt;dbl&gt;, abs_lymph_0_cat &lt;dbl&gt;, abs_mono_0_cat &lt;dbl&gt;, ## # creat_0_cat &lt;dbl&gt;, crp_0_cat &lt;dbl&gt;, ddimer_0_cat &lt;dbl&gt;, ldh_0_cat &lt;dbl&gt;, ## # Trop_72h &lt;dbl&gt;, abs_neut_3_cat &lt;dbl&gt;, abs_lymph_3_cat &lt;dbl&gt;, ## # abs_mono_3_cat &lt;dbl&gt;, creat_3_cat &lt;dbl&gt;, crp_3_cat &lt;dbl&gt;, … ## clean names of the merged dataset #### default option is snake case janitor::clean_names(df) ## # A tibble: 384 × 44 ## subject_id covid age_cat bmi_cat heart lung kidney diabetes htn immuno ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 1 1 4 0 0 0 0 0 0 ## 2 2 1 2 2 0 0 0 0 0 0 ## 3 3 1 3 4 0 1 0 0 0 0 ## 4 4 1 1 2 0 0 0 0 0 0 ## 5 5 1 3 3 0 0 0 1 1 0 ## 6 6 1 1 1 1 0 0 0 0 0 ## 7 7 1 2 2 0 0 0 1 0 0 ## 8 8 0 4 3 0 0 0 1 1 1 ## 9 9 1 5 2 0 1 1 0 1 0 ## 10 10 0 2 2 0 0 0 0 0 0 ## # … with 374 more rows, and 34 more variables: resp_symp &lt;dbl&gt;, ## # fever_sympt &lt;dbl&gt;, gi_symp &lt;dbl&gt;, d0_draw &lt;dbl&gt;, d3_draw &lt;dbl&gt;, ## # d7_draw &lt;dbl&gt;, de_draw &lt;dbl&gt;, acuity_0 &lt;dbl&gt;, acuity_3 &lt;dbl&gt;, ## # acuity_7 &lt;dbl&gt;, acuity_28 &lt;dbl&gt;, acuity_max &lt;dbl&gt;, abs_neut_0_cat &lt;dbl&gt;, ## # abs_lymph_0_cat &lt;dbl&gt;, abs_mono_0_cat &lt;dbl&gt;, creat_0_cat &lt;dbl&gt;, ## # crp_0_cat &lt;dbl&gt;, ddimer_0_cat &lt;dbl&gt;, ldh_0_cat &lt;dbl&gt;, trop_72h &lt;dbl&gt;, ## # abs_neut_3_cat &lt;dbl&gt;, abs_lymph_3_cat &lt;dbl&gt;, abs_mono_3_cat &lt;dbl&gt;, … "],["data-file-management-using-the-guerilla-method.html", "4 Data &amp; File Management using the Guerilla Method 4.1 Example", " 4 Data &amp; File Management using the Guerilla Method File management on a laptop isn’t very different from paper file organization. The most efficient way to structure file organization is to make a Docs, or Document folder which contains a folder for each project. The project folder should contain: Folder named data Which contain all raw data for the project. Folder named images A file containing all references All files that contain the analysis/code A README file 4.1 Example if (!require(tidyverse)) install.packages(&quot;tidyverse&quot;) if (!require(magrittr)) install.packages(&quot;magrittr&quot;) if (!require(fs)) install.packages(&quot;fs&quot;) ## show folder structure of the bookdown project fs::dir_tree(here::here()) ## C:/Users/cherinjuliette/Documents/DSFB2/dsfb2_bookdown ## ├── 001_2_dsfb2_celegans.Rmd ## ├── 001_dsfb2_reproducibility.Rmd ## ├── 002_dsfb2_datamanagement.Rmd ## ├── 005_dsfb2_projectintro.Rmd ## ├── 007_dsfb2_dengue_flu.Rmd ## ├── 008_dsfb2_rpackage.Rmd ## ├── 009_dsfb2_covid.Rmd ## ├── 010_references_empty.Rmd ## ├── 404.html ## ├── august_october_2020_ipsos.tiff ## ├── book.bib ## ├── data ## │ ├── dengue_data_tidy.csv ## │ ├── dengue_tidy.csv ## │ ├── dengue_tidy.rds ## │ ├── flu_data_tidy.csv ## │ ├── flu_tidy.csv ## │ ├── flu_tidy.rds ## │ ├── gapminder.csv ## │ ├── gapminder.rds ## │ ├── gapminder_messy.csv ## │ └── gapminder_messy.rds ## ├── dsfb2_bookdown.Rproj ## ├── images ## │ ├── 009_plot1.png ## │ ├── 009_plot2.png ## │ ├── 009_plot3.png ## │ └── 00_portfolio_demo.png ## ├── index.Rmd ## ├── packages.bib ## ├── preamble.tex ## ├── raw_data ## │ ├── 007_dengue.csv ## │ ├── 007_flu.csv ## │ ├── 009_data.csv ## │ ├── august_october_2020.csv ## │ ├── CE.LIQ.FLOW.062_Tidydata.xlsx ## │ └── MGH_Olink_COVID_Apr_27_2021 ## │ ├── MGH_COVID_Clinical_Info.txt ## │ └── Variable_descriptions_2021-04-27.xlsx ## ├── README.md ## ├── references.bib ## ├── style.css ## ├── _book ## │ ├── 404.html ## │ ├── aside.html ## │ ├── automating-peak-identification-using-r.html ## │ ├── blocks.html ## │ ├── cross.html ## │ ├── data-file-management-using-the-guerilla-method.html ## │ ├── dose-response-analysis-of-c.-elegans.html ## │ ├── evaluating-covid-19-cases-and-deaths.html ## │ ├── evaluating-the-global-dengue-fever-and-flu-cases-in-r.html ## │ ├── footnotes-and-citations.html ## │ ├── hello-bookdown.html ## │ ├── images ## │ │ ├── 009_plot1.png ## │ │ ├── 009_plot2.png ## │ │ └── 009_plot3.png ## │ ├── index.html ## │ ├── libs ## │ │ ├── anchor-sections-1.1.0 ## │ │ │ ├── anchor-sections-hash.css ## │ │ │ ├── anchor-sections.css ## │ │ │ └── anchor-sections.js ## │ │ ├── crosstalk-1.2.0 ## │ │ │ ├── css ## │ │ │ │ └── crosstalk.min.css ## │ │ │ └── js ## │ │ │ └── crosstalk.min.js ## │ │ ├── gitbook-2.6.7 ## │ │ │ ├── css ## │ │ │ │ ├── fontawesome ## │ │ │ │ │ └── fontawesome-webfont.ttf ## │ │ │ │ ├── plugin-bookdown.css ## │ │ │ │ ├── plugin-clipboard.css ## │ │ │ │ ├── plugin-fontsettings.css ## │ │ │ │ ├── plugin-highlight.css ## │ │ │ │ ├── plugin-search.css ## │ │ │ │ ├── plugin-table.css ## │ │ │ │ └── style.css ## │ │ │ └── js ## │ │ │ ├── app.min.js ## │ │ │ ├── clipboard.min.js ## │ │ │ ├── jquery.highlight.js ## │ │ │ ├── plugin-bookdown.js ## │ │ │ ├── plugin-clipboard.js ## │ │ │ ├── plugin-fontsettings.js ## │ │ │ ├── plugin-search.js ## │ │ │ └── plugin-sharing.js ## │ │ ├── htmlwidgets-1.5.4 ## │ │ │ └── htmlwidgets.js ## │ │ ├── jquery-3.6.0 ## │ │ │ └── jquery-3.6.0.min.js ## │ │ ├── plotly-binding-4.10.0.9001 ## │ │ │ └── plotly.js ## │ │ ├── plotly-htmlwidgets-css-2.11.1 ## │ │ │ └── plotly-htmlwidgets.css ## │ │ ├── plotly-main-2.11.1 ## │ │ │ └── plotly-latest.min.js ## │ │ └── typedarray-0.1 ## │ │ └── typedarray.min.js ## │ ├── main.html ## │ ├── making-r-package-rcolorutrecht.html ## │ ├── parts.html ## │ ├── references.html ## │ ├── reproducibility-in-data-science.html ## │ ├── search_index.json ## │ ├── sharing-your-book.html ## │ ├── style.css ## │ ├── _main.epub ## │ ├── _main.pdf ## │ ├── _main.tex ## │ └── _main_files ## │ └── figure-html ## │ ├── nice-fig-1.png ## │ ├── normalize negative control-1.png ## │ ├── plot-1.png ## │ ├── plot2-1.png ## │ ├── riffomonas-1.png ## │ ├── scatter plot-1.png ## │ ├── standard dengue graph-1.png ## │ ├── standard flu graph-1.png ## │ ├── standard flu graph-2.png ## │ └── together-1.png ## ├── _bookdown.yml ## ├── _bookdown_files ## ├── _main.Rmd ## ├── _main_files ## │ └── figure-html ## │ ├── normalize negative control-1.png ## │ ├── plot-1.png ## │ ├── plot2-1.png ## │ ├── riffomonas-1.png ## │ ├── scatter plot-1.png ## │ ├── standard dengue graph-1.png ## │ ├── standard flu graph-1.png ## │ ├── standard flu graph-2.png ## │ └── together-1.png ## └── _output.yml "],["automating-peak-identification-using-r.html", "5 Automating Peak Identification using R", " 5 Automating Peak Identification using R The Naja Pallida snake is a native of Western Africa. When threatened, it shoots venom into the eyes of its adversary, briefly blinding them and giving them time to flee. This impact is explored in zoological laboratories. When a snake bites a human, little cloats form {Bittenbinder et al. (2018)}, which might cause the individual to die (ABC Science). The Institute for Life Sciences is well-known for its participation in snake venom research. This is because a previous pupil, Jory van Thiel, has been infatuated with snakes since he was a child. He once came to see us at college and told us about his fascination with snakes, how he acted in self-defense rather than malice, and how he even had his own pet snake. During his travels to Asia a snake spat venom in his eyes which blinded him temporarily and made him understand the defence mechanism of the Naja Pallida {“Leidse Biologiestudenten in Diverse Media over Spugende Cobra’s” (n.d.)}. A study which got him published in Science! Snakes, as Jory once noted, are normally fairly sweet, but that doesn’t mean their means of self-defense isn’t harmful, if not lethal. In the laboratory, researchers are attempting to establish what makes the venom so lethal, as well as whether there are any benefits to the venom that could be used in the development of an anti-venom or the therapy of certain heart diseases {Kazandjian et al. (2021)}. Rat hearts were exposed to venom ex vivo in order to uncover a possible cure for excessive blood loss, specific cardiac diseases, and to find an anti-venom. This is accomplished using a Langendorff setup that includes a heart attached to the Langendorff and venom administered through a tube. This setup is done at the Institute of Life Sciences with venom from the Naja Pallida and the Crotalus atrox {McKeller and Pérez (n.d.)}. These venoms were tested on rat hearts ex vivo and human neuroblastoma cells (SKNAS) in vitro. When we look at the results in vitro, we can observe that cells deteriorate quickly. This effect is reduced when the inhibitor Varespladib is added {Lewin et al. (2016)}. For this reason the compound Varespladib is researched as a possible anti-dote {Zinenko, Tovstukha, and Korniyenko (2020)}. When considering the effect seen ex vivo, which means the venom is administered via the Langendorff setup, we can see the venom’s effect on the heart, but we can also see the peak pattern that is formed. The reason for this is that when the rat’s heart is removed, Ringer buffer is provided, causing the heart to beat somewhat longer than usual when taken from the body. When the venom is delivered, we can detect a peak pattern that indicates cardiac contractions. The researchers on the lab manually calculated data from the experiment, such as the number of peaks, maximal contraction force (the peak height), and beats per minute. The disadvantage is that the technique is extremely error-prone, and bias can readily creep in. This method is automated to avoid avoidable errors and save time for the researchers. I participated in this project with two other students, which was commissioned by the Institute of Life Sciences’ Zoology department and was carried out under the supervision of Dr. Micheal Liem. In R, a for loop was used to automate the peak identification process. We created a for-loop that examines the data file and determines if a peak is a peak by determining whether it has crossed a “hill.” When you first enter the dataset, it will rise upwards with a peak before descending again. Every time the loop runs, it checks this procedure and records the number of peaks in a new file. In addition, another loop was created that calculates the beats per minute (bpm) during a 5-second period. This appears to be a very short time, but keep in mind that an experiment like this one typically lasts 30 to 45 minutes and that physiological consequences like cell degregation and blood clot development occur extremely quickly when exposed to snake venom. As with any experiment that produces peaks, we must also consider that some noise will be introduced. Noise is defined as peaks that appear on the graph but were not caused by the experiment. They were most likely caused by an analist accidentally bumping against the table, improper Langendorff setups, or any number of minor factors. To reduce the noise from the graph, we used a technique known as thresholding. This means that we examine a graph and determine how high the peaks are on average. This is the contraction force or strength. Peaks that are significantly smaller than the general peaks will not pass the threshold and will be filtered out. Sounds simple enough, doesn’t it? Well, we discovered that the more experiments performed, the more different the peak graph may appear. Meaning, if an analist is jittery after his seventh cup of coffee and is having a clumsy day, significantly more noise will be noticed on the graph, and they may not all be the same height. Another explanation could be that a different setup was employed, or that the venom was used at a different concentration. To provide the commissioning party with the most accurate information, we have chosen to let the analist chose the threshold for themself. This is done by writing a function in the loop which doesn’t establish a fixed value as a threshold but rather lets the user choose it. Even while sometimes we forget the rest of the Institute for Life Sciences doesn’t love the language R as much as we do, it did dawn on us that we couldn’t simply hand in an R script and call it a day. For this reason we made a R Shiny app, which is an UI written purely with R and a little HTML and CSS for the look. In this app, the user will be presented with a README, and a page where they may upload the data file. The graphs will then be generated for them and they can afterwards choose a threshold. This is an ungoing project. Want to keep track? Check out the project repo on GitHub! Also check out my repository for the minor course I followed to see how I use bookdown to combine all my separate projects. References "],["evaluating-the-global-dengue-fever-and-flu-cases-in-r.html", "6 Evaluating the global Dengue Fever and Flu cases in R 6.1 Conclusions on the dengue dataset", " 6 Evaluating the global Dengue Fever and Flu cases in R Google.org provides a number of datasets on Dengue Fever and flue cases. I downloaded two files that contained the number of dengue fever cases and flu cases which were already present in the GitHub repository of the course. These files provide cases from 2002 till 2015. I began my analysis with the following steps: Manual download of the Dengue Fever dataset from the dsfb2 repository. Manual download of the Flu Fever dataset from the dsfb2 repository. Clean and tidy the data Write the data away in the folder data Make a SQL database of the data using RPostgreSQL Data visualization Conclusion Data import of Dengue dataset dengue &lt;- read_csv(here::here(&quot;raw_data/007_dengue.csv&quot;), ## ignores the rows containing metadata skip = 11) Data import of the Flu dataset flu &lt;- read_csv(here::here(&quot;raw_data/007_flu.csv&quot;), ## ignore rows with metadata skip = 11) gapminder &lt;- read_builtin(&quot;gapminder&quot;) ## inspect the datasets dplyr::glimpse(gapminder) ## Rows: 10,545 ## Columns: 9 ## $ country &lt;fct&gt; &quot;Albania&quot;, &quot;Algeria&quot;, &quot;Angola&quot;, &quot;Antigua and Barbuda&quot;… ## $ year &lt;int&gt; 1960, 1960, 1960, 1960, 1960, 1960, 1960, 1960, 1960,… ## $ infant_mortality &lt;dbl&gt; 115.40, 148.20, 208.00, NA, 59.87, NA, NA, 20.30, 37.… ## $ life_expectancy &lt;dbl&gt; 62.87, 47.50, 35.98, 62.97, 65.39, 66.86, 65.66, 70.8… ## $ fertility &lt;dbl&gt; 6.19, 7.65, 7.32, 4.43, 3.11, 4.55, 4.82, 3.45, 2.70,… ## $ population &lt;dbl&gt; 1636054, 11124892, 5270844, 54681, 20619075, 1867396,… ## $ gdp &lt;dbl&gt; NA, 13828152297, NA, NA, 108322326649, NA, NA, 966778… ## $ continent &lt;fct&gt; Europe, Africa, Africa, Americas, Americas, Asia, Ame… ## $ region &lt;fct&gt; Southern Europe, Northern Africa, Middle Africa, Cari… dplyr::glimpse(dengue) ## Rows: 659 ## Columns: 11 ## $ Date &lt;date&gt; 2002-12-29, 2003-01-05, 2003-01-12, 2003-01-19, 2003-01-2… ## $ Argentina &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, 0.046, 0.048, 0.051, 0.051, 0.… ## $ Bolivia &lt;dbl&gt; 0.101, 0.143, 0.176, 0.173, 0.146, 0.160, 0.225, 0.109, 0.… ## $ Brazil &lt;dbl&gt; 0.073, 0.098, 0.119, 0.170, 0.138, 0.202, 0.179, 0.239, 0.… ## $ India &lt;dbl&gt; 0.062, 0.047, 0.051, 0.032, 0.040, 0.038, 0.019, 0.008, 0.… ## $ Indonesia &lt;dbl&gt; 0.101, 0.039, 0.059, 0.039, 0.112, 0.049, 0.060, 0.039, 0.… ## $ Mexico &lt;dbl&gt; NA, NA, 0.071, 0.052, 0.048, 0.041, 0.042, 0.049, 0.054, 0… ## $ Philippines &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 0.059,… ## $ Singapore &lt;dbl&gt; 0.059, 0.059, 0.238, 0.175, 0.164, 0.163, 0.150, 0.144, 0.… ## $ Thailand &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Venezuela &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, 0.139, 0.137, 0.168, 0.169, 0.… dplyr::glimpse(flu) ## Rows: 659 ## Columns: 30 ## $ Date &lt;date&gt; 2002-12-29, 2003-01-05, 2003-01-12, 2003-01-19, 2003-… ## $ Argentina &lt;dbl&gt; NA, NA, NA, NA, NA, 136, 145, 141, 135, 134, 136, 134,… ## $ Australia &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Austria &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Belgium &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Bolivia &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, 426, 427, 460, 541, 54… ## $ Brazil &lt;dbl&gt; 174, 162, 174, 162, 131, 151, 184, 162, 194, 177, 223,… ## $ Bulgaria &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Canada &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Chile &lt;dbl&gt; NA, NA, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 1, 1, 1, 2… ## $ France &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Germany &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Hungary &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Japan &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Mexico &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Netherlands &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `New Zealand` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Norway &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Paraguay &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Peru &lt;dbl&gt; 329, 315, 314, 267, 241, 227, 250, 236, 274, 270, 312,… ## $ Poland &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Romania &lt;dbl&gt; NA, NA, NA, NA, NA, NA, 664, 736, 740, 864, 824, 819, … ## $ Russia &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `South Africa` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Spain &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Sweden &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Switzerland &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Ukraine &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ `United States` &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA… ## $ Uruguay &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, 105, 102, … Tidy data of the Flue dataset ## tidy the dengue dataset ## Put all countries in 1 column, and the flu cases in 1 column dengue_tidy &lt;- dengue %&gt;% ## selecting all columns by hand is tedious ## Here i select column Argentia till Venezuela using : pivot_longer( cols = Argentina:Venezuela, names_to = &quot;Country&quot;, values_to = &quot;dengue_cases&quot; ) ## tidy the flu dataset ## Put all countries in 1 column and cases in another column flu_tidy &lt;- flu %&gt;% pivot_longer( cols = Argentina:Uruguay, names_to = &quot;Country&quot;, values_to = &quot;flu_cases&quot; ) ## DENGUE ## split the column Date to three columns named Year, Month and Day dengue_tidy &lt;- dengue_tidy %&gt;% separate(Date, c(&quot;Year&quot;, &quot;Month&quot;, &quot;Day&quot;)) ## FLU ## split the column Date to three columns named Year, Month and Day flu_tidy &lt;- flu_tidy %&gt;% separate(Date, c(&quot;Year&quot;, &quot;Month&quot;, &quot;Day&quot;)) ## correct data class for the flu dataset flu_tidy$Year &lt;- as.numeric(flu_tidy$Year) flu_tidy$Month &lt;- as.numeric(flu_tidy$Month) flu_tidy$Day &lt;- as.numeric(flu_tidy$Day) ## correct data class for the dengue dataset dengue_tidy$Year &lt;- as.numeric(dengue_tidy$Year) dengue_tidy$Month &lt;- as.numeric(dengue_tidy$Month) dengue_tidy$Day &lt;- as.numeric(dengue_tidy$Day) Save the clean and tidy data in a new CSV file using the write function ## write the tidy data into a new file ## the location of the files will be in folder data ## write away the tidy flu dataset flu_tidy %&gt;% write.csv(file = &quot;./data/flu_tidy.csv&quot;) ## write away the tidy dengue dataset dengue_tidy %&gt;% write.csv(file = &quot;./data/dengue_tidy.csv&quot;) ## write away the gapminder dataset gapminder %&gt;% write.csv(file = &quot;./data/gapminder.csv&quot;) ## save the data in a RDS file also saveRDS(gapminder, file = &quot;./data/gapminder.rds&quot;) saveRDS(dengue_tidy, file = &quot;./data/dengue_tidy.rds&quot;) saveRDS(flu_tidy, file = &quot;./data/flu_tidy.rds&quot;) ## exporting to DBeaver requires a password which is unique for all users ## for safety reasons I will be omitting this information ## this analysis is still reproducible if you copy the code and insert your own password ## export the new files into DBeaver using RPostgres con &lt;- dbConnect(RPostgres::Postgres(), dbname = &quot;workflowsdb&quot;, host = &quot;localhost&quot;, port = &quot;5432&quot;, user = &quot;postgres&quot;, password = &quot;2022&quot;) dbWriteTable(con, &quot;flu_tidy&quot;, flu_tidy) dbWriteTable(con, &quot;dengue_tidy&quot;, dengue_tidy) dbWriteTable(con, &quot;gapminder&quot;, gapminder) dbDisconnect(con) ## Inspect the files in DBeaver ## SELECT dengue_cases, country ## FROM dengue tidy order ## BY dengue_cases asc ## SELECT dengue_cases, country ## FROM dengue tidy order ## BY dengue_cases desc ## do this for all 3 files. After inspecting the data in DBeaver, import the files back into R ## import the data into R again after inspecting in DBeaver ## using RPostgres gapminder &lt;- dbReadTable(con, &quot;gapminder&quot;) dengue &lt;- dbReadTable(con, &quot;dengue_tidy&quot;) flu &lt;- dbReadTable(con, &quot;flu_tidy&quot;) Data visualization Is the flu and dengue fever more prevalent in certain areas? Let’s check ## clean variables names ## default option is snake case flu_tidy &lt;- janitor::clean_names(flu_tidy) flu_1 &lt;- flu_tidy %&gt;% group_by(year) %&gt;% na.omit() %&gt;% ggplot(aes(x = year, y = flu_cases, fill = year)) + geom_col() + theme_minimal() + labs(title = &quot;Evaluating the number of flu cases&quot;, subtitle = &quot;Have flu cases risen over the years?&quot;, x = &quot;Year&quot;, y = &quot;Number of flu cases&quot;, caption = &quot;Data source: Course instructors&quot;) ## Check per country flu_1 + facet_wrap(~country) flu_1 ## clean variables names ## default option is snake case dengue_tidy &lt;- janitor::clean_names(dengue_tidy) dengue_1 &lt;- dengue_tidy %&gt;% group_by(year) %&gt;% na.omit() %&gt;% ggplot(aes(x = year, y = dengue_cases, fill = year)) + geom_col() + theme_minimal() + labs(title = &quot;Evaluating the number of flu cases&quot;, subtitle = &quot;Have flu cases risen over the years?&quot;, x = &quot;Year&quot;, y = &quot;Number of flu cases&quot;, caption = &quot;Data source: Course instructors&quot;) ## let&#39;s see the difference between countries dengue_1 + facet_grid(~country) Conclusions on the flu dataset When considering the number of flu cases globally, we can see that the highest occurence of the flu is in Spain, followed by Canada and the US. In contrast, the lowest flu occurences are found in Sweden, followed by Chile and New Zealand. The reason for this is unknown. To establish significance we could do statistical testing. 6.1 Conclusions on the dengue dataset When looking at the graph that shows dengue occurrences, we can see that the highest number of cases are seen in Venezuele, followed by Indonesia and Brazil. Dengue fever develops after infection with the Flaviviridae virus carried by mosquitoes. These mosquitoes are more prevalent in countries with warmer climates, which might explain the high occurrences. Let’s do some joins We can already tell a lot by standard visualization as displayed above, but we want to compare the two occurances. flu_dengue &lt;- full_join(flu_tidy, dengue_tidy, by = c(&quot;country&quot;, &quot;year&quot;), suffix = c(&quot;_flu&quot;, &quot;_dengue&quot;)) ## let&#39;s also join the data from the gapminder dataset with the flu and dengue dataset gapminder_flu_dengue &lt;- inner_join(flu_dengue, gapminder, by = c(&quot;country&quot;, &quot;year&quot;)) Visualize the cases of flu per country # plot occurrences of flu and dengue per region flu_country &lt;- gapminder_flu_dengue %&gt;% ggplot() + geom_col(aes(x = country, y = flu_cases, fill = country)) + theme_minimal() + scale_fill_rcolorUtrecht(palette = &quot;hu&quot;) + ## turn the x axis labels by a 45 degree angle theme(axis.text.x = element_text(angle = 45, hjust = 1), ## legend is unnecessary legend.position = &quot;none&quot; ) + ## Explain the graph labs(title = &quot;Flu cases per country&quot;, x = &quot;&quot;, y = &quot;Flu cases&quot;) Visualize the cases of dengue fever per country dengue_country &lt;- gapminder_flu_dengue %&gt;% ggplot() + geom_col(aes(x = country, y = dengue_cases, fill = country)) + theme_bw() + scale_fill_rcolorUtrecht(palette = &quot;hu&quot;) + ## turn the x axis label 45 degrees theme(axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;none&quot;) + ## explain the graph labs(title = &quot;Cases of Dengue Fever per country&quot;, x = &quot;&quot;, y = &quot;Cases of Dengue Fever&quot;) grid.arrange(flu_country, dengue_country, nrow = 1) Conclusions after joining Joining the dataset provides us with a singular object that contains data on all three diseases. This helps put things in perspective, but as we see in the graphs above, the conclusions previously drawn remains the same. "],["making-r-package-rcolorutrecht.html", "7 Making R package rcolorUtrecht", " 7 Making R package rcolorUtrecht Art is the Queen of all Sciences Communicating Knowledge to All the Generations of the World. (Leonardo da Vinci) The Dutch city Utrecht is one of the most beautiful places in the world, and a beacon of art and education, housing more than 21 universities and colleges and 400 art installations. Not long ago when I was lying sick in bed, scrolling the internet for some distraction and at photographs of art pieces, when I stumbled upon the R package by Edwin Thoen (GitHub: EdwinTh) named dutchmasters. I was immediately inspired. As a Data Scientist you are constantly making graphs that convey to someone either a difference or correlation. That proces is important because looking at large files of data can be daunting and makes us prone to making mistakes. To make a statistical graphs more appealing, we use distinctive colors. To add to the color palettes currently available in R, I used the beauty of a city. After gathering some photographs of street art found in Utrecht, I extracted the color palettes with the site ginifab.com. The hex codes from the images were stored in a variable, specific to every art piece. The saving of those color codes means that the package that I named rcolorUtrecht now contains a function with which you can make a graph using the color codes I stored in that function. My next step was to use a function for the scale_fill option and the scale_color option. The colors will be the same however when using custom color palette packages in R, and let’s say we want to make a bar chart that compares the honey production per month in a given year, we must add the code scale_fill_rcolorUtrecht(palette = “the_wonders”). Now let’s say we want to make a scatterplot that seeks to verify whether there is a correlation between cat breeds and tail lengths (yes, I chose this example for a specific reason) when you would use the code scale_color_rcolorUtrecht(palette = “the_wonders”). Lastly, I added the every elusive vignettes This is kind of like a instruction manual you receive when buying an appliance. This way when you install my package by running devtools::install_github(&quot;cherjuliette/rcolorUtrecht&quot;) and are wondering how to use the package, you may run the code… help(package = &quot;rcolorUtrecht&quot;) Let me show you what a graph using my package would look like. ## package that stores the starwars dataset if (!require(tidyverse)) install.packages(&quot;tidyverse&quot;) ## visualize plot &lt;- starwars %&gt;% filter(hair_color == &quot;black&quot; | hair_color == &quot;brown&quot;) %&gt;% drop_na(sex) %&gt;% ggplot(aes(x = hair_color, fill = sex)) + geom_bar(position = &quot;dodge&quot;, alpha = 0.8) + theme_minimal() + theme(panel.grid.major = element_blank()) ## color palette plot + scale_fill_rcolorUtrecht(palette = &quot;hu&quot;) Wondering about the package? Or do you just want to see the source code? Take a look at my GitHub repository References Hogeschool Utrecht/Institute for Life Sciences at the Uithof City ambassador group Thirty030, member patatjes4life IG: patatjes4life De Wonderen/The Wonders mural in Pijlsweerd by Boukje Lootsma and Germa Borst [Stories from the Neighborhood in Dichterswijk by Munir de Vries] (www.duic.nl/cultuur/gigantische-muurschildering-verhalen-bewoners-croeselaan/) IG: https://www.instagram.com/munir_de_vries/?hl=en Ducdalf met Schepen (1978)/ Ducdalf with Ships (1978) by Anne P. Boer in the Adelaarstraat Nijntje/Miffy at the Mariaplaats by De Strakke Hand Groceries mural above the Albert Heijn grocery shop in Amsterdamse Straatweg 367 by Jan is De Man IG: https://www.instagram.com/janisdeman/?hl=en Train Station from the Past at Meidoornstraat by De Verfdokter Derk by Derk Wessels and Jan is De Man at Lauwerecht 55 De Walvis/The Wale by Studio KCA at the Tivolivredenburg Glimpse into the Past above the Ibis Hotel at Bizetlaan by De Strakke Hand Geese at the Gansstraat 64 by De Strakke Hand 3D organs at the Berlijnplein bij Leon Keer Birds mural at the Vogelenbuurt by Jan is De Man Phase Constract Microscope of Caroline Bleeker by De Strakke Hand Utrecht University at the Domplein "],["evaluating-covid-19-cases-and-deaths.html", "8 Evaluating COVID-19 cases and deaths", " 8 Evaluating COVID-19 cases and deaths Introduction Previously, I reproduced the analysis by Riffomonas to demonstrate the value of reproducible research as well as grade the analysis on reproducibility. While the analysis got an A on reproducibility, it also showed that France showed the highest reluctance to get a COVID-19 vaccine in August 2020. From the ECDC website I downloaded a dataset which contains the number of COVID-19 cases and deaths from 2020 till 2022. In this analysis I use parameters to plot the number of COVID-19 cases and deaths by COVID-19 (related complications). # data import ## from folder raw_data df &lt;- read.csv(here::here(&quot;raw_data&quot;, &quot;009_data.csv&quot;)) # save the plot in an object to combine it later using cowplot df &lt;- df %&gt;% ## filter all data for France dplyr::filter(countriesAndTerritories == params$country, year == params$year, month &gt;= params$period_start, month &lt;= params$period_end) # the column dateRep gives the full date of the data collected but ## is of the data class character ## change the class type of dateRep to numeric by classifying it as a date df$dateRep &lt;- as.Date(df$dateRep, format = &quot;%d/%m/%Y&quot;) # plot the number of reported COVID-19 cases in the year 2020 cases &lt;- df %&gt;% ggplot(aes(x = dateRep, y = cases)) + ## size of the points geom_point(size = 1) + ## line color geom_line(aes(color = &quot;red&quot;)) + ## explain the graph labs(title = paste(&quot;Number of reported \\n COVID-19 cases from&quot;, params$period_start, &quot;to&quot;, params$period_end, &quot;in&quot;, params$year, &quot;for&quot;, params$country), x = &quot;Month&quot;, y = &quot;Reported COVID-19 cases&quot;) + ## legend is unnecessary theme(legend.position = none) + ## choose a theme to your liking theme_bw() ## let&#39;s take a look cases plot1 # plot the number of deaths by COVID-19 in the year 2020 deaths &lt;- df %&gt;% ggplot(aes(x = dateRep, y = deaths)) + ## size of the points geom_point(size = 1) + ## color of the lines geom_line(color = &quot;red&quot;) + ## explain the graph labs(title = paste(&quot;Number of deaths caused \\n by COVID-19 in&quot;, params$period_start, &quot;to&quot;, params$period_end, &quot;in&quot;, params$year, &quot;for&quot;, params$country), x = &quot;Month&quot;, y = &quot;Number of deaths caused by COVID-19&quot;) + theme(legend.position = none)+ ## choose a theme to your liking theme_bw() ## let&#39;s take another look deaths plot2 Combine both plots to visualize the distinction. plot_grid(cases, deaths, label_size = 8) plot3 What to take a look under the hood? See the source code here "],["references.html", "9 References", " 9 References "]]
